{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Tensor Flow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTLujOWmJxS-"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzpgArV9KO3N"
      },
      "source": [
        "credit_card = pd.read_csv('https://raw.githubusercontent.com/Andikazidanef15/Introduction-to-Tensor-Flow-in-Python/main/uci_credit_card.csv')\n",
        "housing = pd.read_csv('https://raw.githubusercontent.com/Andikazidanef15/Introduction-to-Tensor-Flow-in-Python/main/kc_house_data.csv')\n",
        "slmnist = pd.read_csv('https://raw.githubusercontent.com/Andikazidanef15/Introduction-to-Tensor-Flow-in-Python/main/slmnist.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YigOKn-0LHhh"
      },
      "source": [
        "# Introduction to TensorFlow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcErgsUyJsDo"
      },
      "source": [
        "## Defining data as constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "dyq1vr3MHlC5",
        "outputId": "147214d9-5562-4c2a-eb15-31370f327f13"
      },
      "source": [
        "credit_card"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default.payment.next.month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>3913.0</td>\n",
              "      <td>3102.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>120000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2682.0</td>\n",
              "      <td>1725.0</td>\n",
              "      <td>2682.0</td>\n",
              "      <td>3272.0</td>\n",
              "      <td>3455.0</td>\n",
              "      <td>3261.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29239.0</td>\n",
              "      <td>14027.0</td>\n",
              "      <td>13559.0</td>\n",
              "      <td>14331.0</td>\n",
              "      <td>14948.0</td>\n",
              "      <td>15549.0</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46990.0</td>\n",
              "      <td>48233.0</td>\n",
              "      <td>49291.0</td>\n",
              "      <td>28314.0</td>\n",
              "      <td>28959.0</td>\n",
              "      <td>29547.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8617.0</td>\n",
              "      <td>5670.0</td>\n",
              "      <td>35835.0</td>\n",
              "      <td>20940.0</td>\n",
              "      <td>19146.0</td>\n",
              "      <td>19131.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>36681.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>29996</td>\n",
              "      <td>220000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>188948.0</td>\n",
              "      <td>192815.0</td>\n",
              "      <td>208365.0</td>\n",
              "      <td>88004.0</td>\n",
              "      <td>31237.0</td>\n",
              "      <td>15980.0</td>\n",
              "      <td>8500.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>5003.0</td>\n",
              "      <td>3047.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>29997</td>\n",
              "      <td>150000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1683.0</td>\n",
              "      <td>1828.0</td>\n",
              "      <td>3502.0</td>\n",
              "      <td>8979.0</td>\n",
              "      <td>5190.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1837.0</td>\n",
              "      <td>3526.0</td>\n",
              "      <td>8998.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>29998</td>\n",
              "      <td>30000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3565.0</td>\n",
              "      <td>3356.0</td>\n",
              "      <td>2758.0</td>\n",
              "      <td>20878.0</td>\n",
              "      <td>20582.0</td>\n",
              "      <td>19357.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22000.0</td>\n",
              "      <td>4200.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>3100.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>29999</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1645.0</td>\n",
              "      <td>78379.0</td>\n",
              "      <td>76304.0</td>\n",
              "      <td>52774.0</td>\n",
              "      <td>11855.0</td>\n",
              "      <td>48944.0</td>\n",
              "      <td>85900.0</td>\n",
              "      <td>3409.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>1926.0</td>\n",
              "      <td>52964.0</td>\n",
              "      <td>1804.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>30000</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47929.0</td>\n",
              "      <td>48905.0</td>\n",
              "      <td>49764.0</td>\n",
              "      <td>36535.0</td>\n",
              "      <td>32428.0</td>\n",
              "      <td>15313.0</td>\n",
              "      <td>2078.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1430.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  LIMIT_BAL  SEX  ...  PAY_AMT5  PAY_AMT6  default.payment.next.month\n",
              "0          1    20000.0    2  ...       0.0       0.0                           1\n",
              "1          2   120000.0    2  ...       0.0    2000.0                           1\n",
              "2          3    90000.0    2  ...    1000.0    5000.0                           0\n",
              "3          4    50000.0    2  ...    1069.0    1000.0                           0\n",
              "4          5    50000.0    1  ...     689.0     679.0                           0\n",
              "...      ...        ...  ...  ...       ...       ...                         ...\n",
              "29995  29996   220000.0    1  ...    5000.0    1000.0                           0\n",
              "29996  29997   150000.0    1  ...       0.0       0.0                           0\n",
              "29997  29998    30000.0    1  ...    2000.0    3100.0                           1\n",
              "29998  29999    80000.0    1  ...   52964.0    1804.0                           1\n",
              "29999  30000    50000.0    1  ...    1000.0    1000.0                           1\n",
              "\n",
              "[30000 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQBUV5W6Km2e"
      },
      "source": [
        "credit_numpy = np.array(credit_card[['EDUCATION','MARRIAGE','AGE','BILL_AMT1']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2a8GwliK3cY",
        "outputId": "89b53b58-1853-444b-cd71-90f4dcb789c0"
      },
      "source": [
        "from tensorflow import constant\n",
        "\n",
        "# Convert the credit_numpy array into a tensorflow constant\n",
        "credit_constant = constant(credit_numpy)\n",
        "\n",
        "# Print constant datatype\n",
        "print('\\n The datatype is:', credit_constant.dtype)\n",
        "\n",
        "# Print constant shape\n",
        "print('\\n The shape is:', credit_constant.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " The datatype is: tf.float64\n",
            "\n",
            " The shape is: TensorShape([30000, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adb1T0FMLFLm"
      },
      "source": [
        "## Defining variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BThtGtjhLGEW",
        "outputId": "0063d752-204f-4f0e-f042-103dc7fc9d71"
      },
      "source": [
        "from tensorflow import Variable\n",
        "\n",
        "# Define the 1-dimensional variable A1\n",
        "A1 = Variable([1, 2, 3, 4])\n",
        "\n",
        "# Print the variable A1\n",
        "print('\\n A1: ', A1)\n",
        "\n",
        "# Convert A1 to a numpy array and assign it to B1\n",
        "B1 = A1.numpy()\n",
        "\n",
        "# Print B1\n",
        "print('\\n B1: ', B1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " A1:  [1 2 3 4]\n",
            "\n",
            " B1:  array([1, 2, 3, 4], dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHmAxQffNBDq"
      },
      "source": [
        "## Performing element-wise multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOfahyBNNBrI",
        "outputId": "a3fc82d5-1309-4337-85c7-af24bc90dd1c"
      },
      "source": [
        "# Define tensors A1 and A23 as constants\n",
        "A1 = constant([1, 2, 3, 4])\n",
        "A23 = constant([[1, 2, 3], [1, 6, 4]])\n",
        "\n",
        "# Define B1 and B23 to have the correct shape\n",
        "B1 = ones_like(A1)\n",
        "B23 = ones_like(A23)\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "C1 = multiply(A1,B1)\n",
        "C23 = multiply(A23,B23)\n",
        "\n",
        "# Print the tensors C1 and C23\n",
        "print('\\n C1: {}'.format(C1.numpy()))\n",
        "print('\\n C23: {}'.format(C23.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " C1: [1 2 3 4]\n",
            "\n",
            " C23: [[1 2 3]\n",
            " [1 6 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_gQI-iTN6cW"
      },
      "source": [
        "Notice how performing element-wise multiplication with tensors of ones leaves the original tensors unchanged."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZS7UYP_N_--"
      },
      "source": [
        "## Making predictions with matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUuZwk19OXju"
      },
      "source": [
        "This process will yield a vector of parameters that can be multiplied by the input data to generate predictions. In this exercise, you will use input data, features, and a target vector, bill, which are taken from a credit card dataset we will use later in the course.\n",
        "\n",
        "The matrix of input data, features, contains two columns: education level and age. The target vector, bill, is the size of the credit card borrower's bill.\n",
        "\n",
        "Since we have not trained the model, you will enter a guess for the values of the parameter vector, params. You will then use matmul() to perform matrix multiplication of features by params to generate predictions, billpred, which you will compare with bill. Note that we have imported matmul() and constant().\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIZdDr52N4Ln",
        "outputId": "ab655c4e-58f3-41c0-908b-da9486b1394a"
      },
      "source": [
        "# Define features, params, and bill as constants\n",
        "features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
        "params = constant([[1000], [150]])\n",
        "bill = constant([[3913], [2682], [8617], [64400]])\n",
        "\n",
        "# Compute billpred using features and params\n",
        "billpred = matmul(features, params)\n",
        "\n",
        "# Compute and print the error\n",
        "error = bill - billpred\n",
        "print(error.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array([[-1687],\n",
            "       [-3218],\n",
            "       [-1933],\n",
            "       [57850]], dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNOLA_6VanB3"
      },
      "source": [
        "## Optimizing with gradients\n",
        "You are given a loss function, , which you want to minimize. You can do this by computing the slope using the GradientTape() operation at different values of x. If the slope is positive, you can decrease the loss by lowering x. If it is negative, you can decrease it by increasing x. This is how gradient descent works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqv_SWdJZ9K0",
        "outputId": "af83eb01-2574-40a4-9d31-b179d6dd1269"
      },
      "source": [
        "def compute_gradient(x0):\n",
        "  \t# Define x as a variable with an initial value of x0\n",
        "\tx = Variable(x0)\n",
        "\twith GradientTape() as tape:\n",
        "\t\ttape.watch(x)\n",
        "        # Define y using the multiply operation\n",
        "\t\ty = multiply(x,x)\n",
        "    # Return the gradient of y with respect to x\n",
        "\treturn tape.gradient(y, x).numpy()\n",
        "\n",
        "# Compute and print gradients at x = -1, 1, and 0\n",
        "print(compute_gradient(-1.0))\n",
        "print(compute_gradient(1.0))\n",
        "print(compute_gradient(0.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-2.0\n",
            "2.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax2zJkTWa4n4"
      },
      "source": [
        "Notice that the slope is positive at x = 1, which means that we can lower the loss by reducing x. The slope is negative at x = -1, which means that we can lower the loss by increasing x. The slope at x = 0 is 0, which means that we cannot lower the loss by either increasing or decreasing x. This is because the loss is minimized at x = 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b0tXFsoclk8"
      },
      "source": [
        "# Linear Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZGSnZVMcodI"
      },
      "source": [
        "## Load data using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuYovXwZcn3E",
        "outputId": "d30ec913-af96-4a9a-83a0-46a3e6ec8207"
      },
      "source": [
        "data_path = 'https://raw.githubusercontent.com/Andikazidanef15/Introduction-to-Tensor-Flow-in-Python/main/kc_house_data.csv'\n",
        "\n",
        "# Load the dataset as a dataframe named housing\n",
        "housing = pd.read_csv(data_path)\n",
        "\n",
        "# Print the price column of housing\n",
        "print(housing['price'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        221900.0\n",
            "1        538000.0\n",
            "2        180000.0\n",
            "3        604000.0\n",
            "4        510000.0\n",
            "           ...   \n",
            "21608    360000.0\n",
            "21609    400000.0\n",
            "21610    402101.0\n",
            "21611    400000.0\n",
            "21612    325000.0\n",
            "Name: price, Length: 21613, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "k90HiBhaeeQw",
        "outputId": "ea20bc23-c206-4a66-cc88-19234e92b0bc"
      },
      "source": [
        "housing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21608</th>\n",
              "      <td>263000018</td>\n",
              "      <td>20140521T000000</td>\n",
              "      <td>360000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1530</td>\n",
              "      <td>1131</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1530</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>98103</td>\n",
              "      <td>47.6993</td>\n",
              "      <td>-122.346</td>\n",
              "      <td>1530</td>\n",
              "      <td>1509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21609</th>\n",
              "      <td>6600060120</td>\n",
              "      <td>20150223T000000</td>\n",
              "      <td>400000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2310</td>\n",
              "      <td>5813</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>2310</td>\n",
              "      <td>0</td>\n",
              "      <td>2014</td>\n",
              "      <td>0</td>\n",
              "      <td>98146</td>\n",
              "      <td>47.5107</td>\n",
              "      <td>-122.362</td>\n",
              "      <td>1830</td>\n",
              "      <td>7200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21610</th>\n",
              "      <td>1523300141</td>\n",
              "      <td>20140623T000000</td>\n",
              "      <td>402101.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1020</td>\n",
              "      <td>1350</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1020</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>98144</td>\n",
              "      <td>47.5944</td>\n",
              "      <td>-122.299</td>\n",
              "      <td>1020</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21611</th>\n",
              "      <td>291310100</td>\n",
              "      <td>20150116T000000</td>\n",
              "      <td>400000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1600</td>\n",
              "      <td>2388</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1600</td>\n",
              "      <td>0</td>\n",
              "      <td>2004</td>\n",
              "      <td>0</td>\n",
              "      <td>98027</td>\n",
              "      <td>47.5345</td>\n",
              "      <td>-122.069</td>\n",
              "      <td>1410</td>\n",
              "      <td>1287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21612</th>\n",
              "      <td>1523300157</td>\n",
              "      <td>20141015T000000</td>\n",
              "      <td>325000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1020</td>\n",
              "      <td>1076</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1020</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>98144</td>\n",
              "      <td>47.5941</td>\n",
              "      <td>-122.299</td>\n",
              "      <td>1020</td>\n",
              "      <td>1357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21613 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id             date  ...  sqft_living15  sqft_lot15\n",
              "0      7129300520  20141013T000000  ...           1340        5650\n",
              "1      6414100192  20141209T000000  ...           1690        7639\n",
              "2      5631500400  20150225T000000  ...           2720        8062\n",
              "3      2487200875  20141209T000000  ...           1360        5000\n",
              "4      1954400510  20150218T000000  ...           1800        7503\n",
              "...           ...              ...  ...            ...         ...\n",
              "21608   263000018  20140521T000000  ...           1530        1509\n",
              "21609  6600060120  20150223T000000  ...           1830        7200\n",
              "21610  1523300141  20140623T000000  ...           1020        2007\n",
              "21611   291310100  20150116T000000  ...           1410        1287\n",
              "21612  1523300157  20141015T000000  ...           1020        1357\n",
              "\n",
              "[21613 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNVmcdW3c-Sk"
      },
      "source": [
        "## Setting the data type\n",
        "In this exercise, you will both load data and set its type. Note that housing is available and pandas has been imported as pd. You will import numpy and tensorflow, and define tensors that are usable in tensorflow using columns in housing with a given data type. Recall that you can select the price column, for instance, from housing using housing['price']."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9iWoOcfc-6B",
        "outputId": "15814a07-a98a-4591-a0cc-e99964ee05ef"
      },
      "source": [
        "# Import numpy and tensorflow with their standard aliases\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Use a numpy array to define price as a 32-bit float\n",
        "price = np.array(housing['price'], np.float32)\n",
        "\n",
        "# Define waterfront as a Boolean using cast\n",
        "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
        "\n",
        "# Print price and waterfront\n",
        "print(price)\n",
        "waterfront"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array([221900., 538000., 180000., ..., 402101., 400000., 325000.],\n",
            "      dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(21613,), dtype=bool, numpy=array([False, False, False, ..., False, False, False])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU2uYYfne3Lg"
      },
      "source": [
        "## Modifying the loss function\n",
        "In this exercise, you will compute the loss within another function called loss_function(), which first generates predicted values from the data and variables. The purpose of this is to construct a function of the trainable model variables that returns the loss. You can then repeatedly evaluate this function for different variable values until you find the minimum. In practice, you will pass this function to an optimizer in tensorflow. Note that features and targets have been defined and are available. Additionally, Variable, float32, and keras are available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR0ys7ZOfC4-"
      },
      "source": [
        "features = constant([1., 2., 3., 4., 5.])\n",
        "targets = constant([ 2.,  4.,  6.,  8., 10.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUmHzwGMdjKT",
        "outputId": "770e0630-9419-41aa-a30a-0ad3d31bb0c9"
      },
      "source": [
        "# Initialize a variable named scalar\n",
        "scalar = Variable(1.0, float32)\n",
        "\n",
        "# Define the model\n",
        "def model(scalar, features = features):\n",
        "  \treturn scalar * features\n",
        "\n",
        "# Define a loss function\n",
        "def loss_function(scalar, features = features, targets = targets):\n",
        "\t# Compute the predicted values\n",
        "\tpredictions = model(scalar, features)\n",
        "    \n",
        "\t# Return the mean absolute error loss\n",
        "\treturn keras.losses.mae(targets, predictions)\n",
        "\n",
        "# Evaluate the loss function and print the loss\n",
        "print(loss_function(scalar).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06f43d3DgK0B"
      },
      "source": [
        "## Set up a linear regression\n",
        "A univariate linear regression identifies the relationship between a single feature and the target tensor. In this exercise, we will use a property's lot size and price. Just as we discussed in the video, we will take the natural logarithms of both tensors, which are available as price_log and size_log.\n",
        "\n",
        "In this exercise, you will define the model and the loss function. You will then evaluate the loss function for two different values of intercept and slope. Remember that the predicted values are given by intercept + features*slope. Additionally, note that keras.losses.mse() is available for you. Furthermore, slope and intercept have been defined as variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "e_Br2eXngt3B",
        "outputId": "863e7bc7-f4e3-43fd-afe9-0319756040e2"
      },
      "source": [
        "housing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21608</th>\n",
              "      <td>263000018</td>\n",
              "      <td>20140521T000000</td>\n",
              "      <td>360000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1530</td>\n",
              "      <td>1131</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1530</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>98103</td>\n",
              "      <td>47.6993</td>\n",
              "      <td>-122.346</td>\n",
              "      <td>1530</td>\n",
              "      <td>1509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21609</th>\n",
              "      <td>6600060120</td>\n",
              "      <td>20150223T000000</td>\n",
              "      <td>400000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2310</td>\n",
              "      <td>5813</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>2310</td>\n",
              "      <td>0</td>\n",
              "      <td>2014</td>\n",
              "      <td>0</td>\n",
              "      <td>98146</td>\n",
              "      <td>47.5107</td>\n",
              "      <td>-122.362</td>\n",
              "      <td>1830</td>\n",
              "      <td>7200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21610</th>\n",
              "      <td>1523300141</td>\n",
              "      <td>20140623T000000</td>\n",
              "      <td>402101.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1020</td>\n",
              "      <td>1350</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1020</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>98144</td>\n",
              "      <td>47.5944</td>\n",
              "      <td>-122.299</td>\n",
              "      <td>1020</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21611</th>\n",
              "      <td>291310100</td>\n",
              "      <td>20150116T000000</td>\n",
              "      <td>400000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1600</td>\n",
              "      <td>2388</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1600</td>\n",
              "      <td>0</td>\n",
              "      <td>2004</td>\n",
              "      <td>0</td>\n",
              "      <td>98027</td>\n",
              "      <td>47.5345</td>\n",
              "      <td>-122.069</td>\n",
              "      <td>1410</td>\n",
              "      <td>1287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21612</th>\n",
              "      <td>1523300157</td>\n",
              "      <td>20141015T000000</td>\n",
              "      <td>325000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1020</td>\n",
              "      <td>1076</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1020</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>98144</td>\n",
              "      <td>47.5941</td>\n",
              "      <td>-122.299</td>\n",
              "      <td>1020</td>\n",
              "      <td>1357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21613 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id             date  ...  sqft_living15  sqft_lot15\n",
              "0      7129300520  20141013T000000  ...           1340        5650\n",
              "1      6414100192  20141209T000000  ...           1690        7639\n",
              "2      5631500400  20150225T000000  ...           2720        8062\n",
              "3      2487200875  20141209T000000  ...           1360        5000\n",
              "4      1954400510  20150218T000000  ...           1800        7503\n",
              "...           ...              ...  ...            ...         ...\n",
              "21608   263000018  20140521T000000  ...           1530        1509\n",
              "21609  6600060120  20150223T000000  ...           1830        7200\n",
              "21610  1523300141  20140623T000000  ...           1020        2007\n",
              "21611   291310100  20150116T000000  ...           1410        1287\n",
              "21612  1523300157  20141015T000000  ...           1020        1357\n",
              "\n",
              "[21613 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL2chqE-gLVj"
      },
      "source": [
        "size = np.array(housing['sqft_lot'], np.float32)\n",
        "\n",
        "price_log = tf.math.log(price)\n",
        "size_log = tf.math.log(size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axE2CiLQhDJ2",
        "outputId": "8f4c89bf-405c-43c1-fa50-b52ac01ab94e"
      },
      "source": [
        "# Define a linear regression model\n",
        "def linear_regression(intercept, slope, features = size_log):\n",
        "\treturn intercept + slope*features\n",
        "\n",
        "# Set loss_function() to take the variables as arguments\n",
        "def loss_function(intercept, slope, features = size_log, targets = price_log):\n",
        "\t# Set the predicted values\n",
        "\tpredictions = linear_regression(intercept, slope, features)\n",
        "    \n",
        "    # Return the mean squared error loss\n",
        "\treturn keras.losses.mse(targets, predictions)\n",
        "\n",
        "# Compute the loss for different slope and intercept values\n",
        "print(loss_function(0.1, 0.1).numpy())\n",
        "print(loss_function(0.1, 0.5).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "145.44653\n",
            "71.866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtqYudzghWt5"
      },
      "source": [
        "## Train a linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H39Cn5PdhXVw"
      },
      "source": [
        "def plot_results(intercept, slope, features, targets):\n",
        "  plt.scatter(features, targets, color = 'black')\n",
        "  plt.plot(features, intercept + features*slope)\n",
        "  plt.xlabel('log(size)')\n",
        "  plt.ylabel('log(price)')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHUfPpsTiVJ0"
      },
      "source": [
        "# Define the intercept and slope\n",
        "intercept = tf.Variable(0.1, np.float32)\n",
        "slope = tf.Variable(0.1, np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "cxOQ3xk2h5yg",
        "outputId": "6a749f25-07f6-4c60-a94a-9bdbc701a883"
      },
      "source": [
        "# Initialize an adam optimizer\n",
        "opt = keras.optimizers.Adam(0.5)\n",
        "\n",
        "for j in range(100):\n",
        "\t# Apply minimize, pass the loss function, and supply the variables\n",
        "\topt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
        "\n",
        "\t# Print every 10th value of the loss\n",
        "\tif j % 10 == 0:\n",
        "\t\tprint(loss_function(intercept, slope).numpy())\n",
        "\n",
        "# Plot data and regression line\n",
        "plot_results(intercept, slope, size_log, price_log)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.2487\n",
            "3.1135912\n",
            "4.9227514\n",
            "4.154534\n",
            "2.3645823\n",
            "1.3899004\n",
            "1.424176\n",
            "1.331604\n",
            "1.2648494\n",
            "1.2258576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMV9dxb4jWOa"
      },
      "source": [
        "## Multiple linear regression\n",
        "In most cases, performing a univariate linear regression will not yield a model that is useful for making accurate predictions. In this exercise, you will perform a multiple regression, which uses more than one feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEkFlaN7jluL"
      },
      "source": [
        "bedrooms = np.array(housing['bedrooms'], np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo6XArZNkJT5"
      },
      "source": [
        "def print_results(param):\n",
        "  dic = {'loss':loss_function(param), 'intercept':param[0], 'slope_1':param[1], 'slope_2':param[2]}\n",
        "  print(dic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T10Pr-7bjW40",
        "outputId": "5a34a36a-e3cc-4dea-a7a7-fc664488ce68"
      },
      "source": [
        "params = Variable([0.1, 0.05, 0.02])\n",
        "\n",
        "# Define the linear regression model\n",
        "def linear_regression(params, feature1 = size_log, feature2 = bedrooms):\n",
        "\treturn params[0] + feature1*params[1] + feature2*params[2]\n",
        "\n",
        "# Define the loss function\n",
        "def loss_function(params, targets = price_log, feature1 = size_log, feature2 = bedrooms):\n",
        "\t# Set the predicted values\n",
        "\tpredictions = linear_regression(params, feature1, feature2)\n",
        "  \n",
        "\t# Use the mean absolute error loss\n",
        "\treturn keras.losses.mae(targets, predictions)\n",
        "\n",
        "# Define the optimize operation\n",
        "opt = keras.optimizers.Adam()\n",
        "\n",
        "# Perform minimization and print trainable variables\n",
        "for j in range(10):\n",
        "\topt.minimize(lambda: loss_function(params), var_list=[params])\n",
        "\tprint_results(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'intercept': 0.100999996, 'loss': 12.4175406, 'slope_1': 0.051, 'slope_2': 0.0209999979}\n",
            "{'intercept': 0.101999991, 'loss': 12.4041805, 'slope_1': 0.0519999973, 'slope_2': 0.0219999943}\n",
            "{'intercept': 0.102999993, 'loss': 12.3908195, 'slope_1': 0.053, 'slope_2': 0.0229999963}\n",
            "{'intercept': 0.103999987, 'loss': 12.3774576, 'slope_1': 0.0539999977, 'slope_2': 0.0239999928}\n",
            "{'intercept': 0.104999982, 'loss': 12.3640976, 'slope_1': 0.054999996, 'slope_2': 0.0249999892}\n",
            "{'intercept': 0.105999984, 'loss': 12.3507376, 'slope_1': 0.055999998, 'slope_2': 0.0259999912}\n",
            "{'intercept': 0.106999978, 'loss': 12.3373766, 'slope_1': 0.0569999963, 'slope_2': 0.0269999895}\n",
            "{'intercept': 0.107999973, 'loss': 12.3240166, 'slope_1': 0.0579999946, 'slope_2': 0.0279999878}\n",
            "{'intercept': 0.108999968, 'loss': 12.3106546, 'slope_1': 0.0589999929, 'slope_2': 0.0289999861}\n",
            "{'intercept': 0.10999997, 'loss': 12.2972946, 'slope_1': 0.0599999912, 'slope_2': 0.0299999863}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4beYeQgQlu98"
      },
      "source": [
        "## Preparing to batch train\n",
        "Before we can train a linear model in batches, we must first define variables, a loss function, and an optimization operation. In this exercise, we will prepare to train a model that will predict price_batch, a batch of house prices, using size_batch, a batch of lot sizes in square feet. In contrast to the previous lesson, we will do this by loading batches of data using pandas, converting it to numpy arrays, and then using it to minimize the loss function in steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtDFJ1vMlvlQ"
      },
      "source": [
        "# Define the intercept and slope\n",
        "intercept = Variable(10, float32)\n",
        "slope = Variable(0.5, float32)\n",
        "\n",
        "# Define the model\n",
        "def linear_regression(intercept, slope, features):\n",
        "\t# Define the predicted values\n",
        "\treturn intercept + slope*features\n",
        "\n",
        "# Define the loss function\n",
        "def loss_function(intercept, slope, targets, features):\n",
        "\t# Define the predicted values\n",
        "\tpredictions = linear_regression(intercept, slope, features)\n",
        "    \n",
        " \t# Define the MSE loss\n",
        "\treturn keras.losses.mse(targets, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "-FHtqDKZmAUu",
        "outputId": "7f317b90-4387-4b50-8326-122e752915d0"
      },
      "source": [
        "# Initialize adam optimizer\n",
        "opt = keras.optimizers.Adam()\n",
        "\n",
        "# Load data in batches\n",
        "for batch in pd.read_csv(data_path, chunksize=100):\n",
        "\tsize_batch = np.array(batch['sqft_lot'], np.int32)\n",
        "\n",
        "\t# Extract the price values for the current batch\n",
        "\tprice_batch = np.array(batch['price'], np.float32)\n",
        "\n",
        "\t# Complete the loss, fill in the variable list, and minimize\n",
        "\topt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
        "\n",
        "# Print trained parameters\n",
        "print(intercept.numpy(), slope.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ec5b15463cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Complete the loss, fill in the variable list, and minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Print trained parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \"\"\"\n\u001b[1;32m    496\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 497\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[1;32m    498\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m           \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-ec5b15463cc8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Complete the loss, fill in the variable list, and minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Print trained parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-7d67c703c442>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(intercept, slope, targets, features)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Define the predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Define the MSE loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-7d67c703c442>\u001b[0m in \u001b[0;36mlinear_regression\u001b[0;34m(intercept, slope, features)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Define the predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Define the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_run_op\u001b[0;34m(a, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    470\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL7Plfg5oGPK"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF11qVL4oInH"
      },
      "source": [
        "## The linear algebra of dense layers\n",
        "There are two ways to define a dense layer in tensorflow. The first involves the use of low-level, linear algebraic operations. The second makes use of high-level keras operations. In this exercise, we will use the first method to construct the network shown in the image below.\n",
        "\n",
        "The input layer contains 3 features -- education, marital status, and age -- which are available as borrower_features. The hidden layer contains 2 nodes and the output layer contains a single node.\n",
        "\n",
        "For each layer, you will take the previous layer as an input, initialize a set of weights, compute the product of the inputs and weights, and then apply an activation function. Note that Variable(), ones(), matmul(), and keras() have been imported from tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xAqeY9lpPTw",
        "outputId": "f54e0eee-db0b-4181-b666-d6b2d8449235"
      },
      "source": [
        "borrower_features = [[ 2.,  2., 43.]]\n",
        "\n",
        "# Initialize bias1\n",
        "bias1 = Variable(1.0)\n",
        "\n",
        "# Initialize weights1 as 3x2 variable of ones\n",
        "weights1 = Variable(ones((3, 2)))\n",
        "\n",
        "# Perform matrix multiplication of borrower_features and weights1\n",
        "product1 = matmul(borrower_features,weights1)\n",
        "\n",
        "# Apply sigmoid activation function to product1 + bias1\n",
        "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
        "\n",
        "# Print shape of dense1\n",
        "print(\"\\n dense1's output shape: {}\".format(dense1.shape))\n",
        "\n",
        "\n",
        "\n",
        "# From previous step\n",
        "bias1 = Variable(1.0)\n",
        "weights1 = Variable(ones((3, 2)))\n",
        "product1 = matmul(borrower_features, weights1)\n",
        "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
        "\n",
        "# Initialize bias2 and weights2\n",
        "bias2 = Variable(1.0)\n",
        "weights2 = Variable(ones((2, 1)))\n",
        "\n",
        "# Perform matrix multiplication of dense1 and weights2\n",
        "product2 = matmul(dense1,weights2)\n",
        "\n",
        "# Apply activation to product2 + bias2 and print the prediction\n",
        "prediction = keras.activations.sigmoid(product2 + bias2)\n",
        "print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n",
        "print('\\n actual: 1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " dense1's output shape: (1, 2)\n",
            "\n",
            " prediction: 0.9525741338729858\n",
            "\n",
            " actual: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBj5l4i9qcA0"
      },
      "source": [
        "Our model produces predicted values in the interval between 0 and 1. For the example we considered, the actual value was 1 and the predicted value was a probability between 0 and 1. This, of course, is not meaningful, since we have not yet trained our model's parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqUsqX-rqlaB"
      },
      "source": [
        "## The low-level approach with multiple example\n",
        "In this exercise, we'll build further intuition for the low-level approach by constructing the first dense hidden layer for the case where we have multiple examples. We'll assume the model is trained and the first layer weights, weights1, and bias, bias1, are available. We'll then perform matrix multiplication of the borrower_features tensor by the weights1 variable. Recall that the borrower_features tensor includes education, marital status, and age. Finally, we'll apply the sigmoid function to the elements of products1 + bias1, yielding dense1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7hkaP1PqceL",
        "outputId": "449bdc24-7530-44e2-c769-207ba96f0f44"
      },
      "source": [
        "borrower_features = tf.cast([[ 3.,  3., 23.],\n",
        "       [ 2.,  1., 24.],\n",
        "       [ 1.,  1., 49.],\n",
        "       [ 1.,  1., 49.],\n",
        "       [ 2.,  1., 29.]], np.float32)\n",
        "weights1 = tf.cast([[-0.6 ,  0.6 ],\n",
        "       [ 0.8 , -0.3 ],\n",
        "       [-0.09, -0.08]],np.float32)\n",
        "\n",
        "# Compute the product of borrower_features and weights1\n",
        "products1 = matmul(borrower_features, weights1)\n",
        "\n",
        "# Apply a sigmoid activation function to products1 + bias1\n",
        "dense1 = keras.activations.sigmoid(products1 + bias1)\n",
        "\n",
        "# Print the shapes of borrower_features, weights1, bias1, and dense1\n",
        "print('\\n shape of borrower_features: ', borrower_features.shape)\n",
        "print('\\n shape of weights1: ', weights1.shape)\n",
        "print('\\n shape of bias1: ', bias1.shape)\n",
        "print('\\n shape of dense1: ', dense1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " shape of borrower_features:  TensorShape([5, 3])\n",
            "\n",
            " shape of weights1:  TensorShape([3, 2])\n",
            "\n",
            " shape of bias1:  TensorShape([])\n",
            "\n",
            " shape of dense1:  TensorShape([5, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOdWdCAtroJp"
      },
      "source": [
        "Note that our input data, borrower_features, is 5x3 because it consists of 5 examples for 3 features. The shape of weights1 is 3x2, as it was in the previous exercise, since it does not depend on the number of examples. Additionally, bias1 is a scalar. Finally, dense1 is 5x2, which means that we can multiply it by the following set of weights, weights2, which we defined to be 2x1 in the previous exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqwjEox7rxyC"
      },
      "source": [
        "## Using the dense layer operation\n",
        "We've now seen how to define dense layers in tensorflow using linear algebra. In this exercise, we'll skip the linear algebra and let keras work out the details. This will allow us to construct the network below, which has 2 hidden layers and 10 features, using less code than we needed for the network with 1 hidden layer and 3 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUTjVTd2rons"
      },
      "source": [
        "borrower_features = tf.cast([[6.96469188e-01, 2.86139339e-01, 2.26851448e-01, 5.51314771e-01,\n",
        "        7.19468951e-01, 4.23106462e-01, 9.80764210e-01, 6.84829712e-01,\n",
        "        4.80931908e-01, 3.92117530e-01],\n",
        "       [3.43178004e-01, 7.29049683e-01, 4.38572258e-01, 5.96778952e-02,\n",
        "        3.98044258e-01, 7.37995386e-01, 1.82491735e-01, 1.75451756e-01,\n",
        "        5.31551361e-01, 5.31827569e-01],\n",
        "       [6.34400964e-01, 8.49431813e-01, 7.24455297e-01, 6.11023486e-01,\n",
        "        7.22443402e-01, 3.22958916e-01, 3.61788660e-01, 2.28263229e-01,\n",
        "        2.93714046e-01, 6.30976140e-01],\n",
        "       [9.21049416e-02, 4.33701187e-01, 4.30862755e-01, 4.93685097e-01,\n",
        "        4.25830305e-01, 3.12261224e-01, 4.26351309e-01, 8.93389165e-01,\n",
        "        9.44160044e-01, 5.01836658e-01],\n",
        "       [6.23952925e-01, 1.15618393e-01, 3.17285478e-01, 4.14826214e-01,\n",
        "        8.66309166e-01, 2.50455379e-01, 4.83034253e-01, 9.85559762e-01,\n",
        "        5.19485116e-01, 6.12894535e-01],\n",
        "       [1.20628662e-01, 8.26340795e-01, 6.03060126e-01, 5.45068026e-01,\n",
        "        3.42763841e-01, 3.04120779e-01, 4.17022198e-01, 6.81300759e-01,\n",
        "        8.75456870e-01, 5.10422349e-01],\n",
        "       [6.69313788e-01, 5.85936546e-01, 6.24903500e-01, 6.74689054e-01,\n",
        "        8.42342436e-01, 8.31949860e-02, 7.63682842e-01, 2.43666381e-01,\n",
        "        1.94222957e-01, 5.72456956e-01],\n",
        "       [9.57125202e-02, 8.85326803e-01, 6.27248943e-01, 7.23416328e-01,\n",
        "        1.61292069e-02, 5.94431877e-01, 5.56785166e-01, 1.58959642e-01,\n",
        "        1.53070509e-01, 6.95529521e-01],\n",
        "       [3.18766415e-01, 6.91970289e-01, 5.54383278e-01, 3.88950586e-01,\n",
        "        9.25132513e-01, 8.41669977e-01, 3.57397556e-01, 4.35914621e-02,\n",
        "        3.04768085e-01, 3.98185670e-01],\n",
        "       [7.04958856e-01, 9.95358467e-01, 3.55914861e-01, 7.62547791e-01,\n",
        "        5.93176901e-01, 6.91701770e-01, 1.51127458e-01, 3.98876280e-01,\n",
        "        2.40855902e-01, 3.43456000e-01],\n",
        "       [5.13128161e-01, 6.66624546e-01, 1.05908483e-01, 1.30894944e-01,\n",
        "        3.21980596e-01, 6.61564350e-01, 8.46506238e-01, 5.53257346e-01,\n",
        "        8.54452491e-01, 3.84837806e-01],\n",
        "       [3.16787899e-01, 3.54264677e-01, 1.71081826e-01, 8.29112649e-01,\n",
        "        3.38670850e-01, 5.52370071e-01, 5.78551471e-01, 5.21533072e-01,\n",
        "        2.68806447e-03, 9.88345444e-01],\n",
        "       [9.05341566e-01, 2.07635865e-01, 2.92489409e-01, 5.20010173e-01,\n",
        "        9.01911378e-01, 9.83630896e-01, 2.57542074e-01, 5.64359069e-01,\n",
        "        8.06968689e-01, 3.94370049e-01],\n",
        "       [7.31073022e-01, 1.61069021e-01, 6.00698590e-01, 8.65864456e-01,\n",
        "        9.83521581e-01, 7.93657899e-02, 4.28347290e-01, 2.04542860e-01,\n",
        "        4.50636476e-01, 5.47763586e-01],\n",
        "       [9.33267102e-02, 2.96860784e-01, 9.27584231e-01, 5.69003761e-01,\n",
        "        4.57412004e-01, 7.53525972e-01, 7.41862178e-01, 4.85790335e-02,\n",
        "        7.08697379e-01, 8.39243352e-01],\n",
        "       [1.65937886e-01, 7.80997932e-01, 2.86536604e-01, 3.06469738e-01,\n",
        "        6.65261447e-01, 1.11392170e-01, 6.64872468e-01, 8.87856781e-01,\n",
        "        6.96311295e-01, 4.40327883e-01],\n",
        "       [4.38214391e-01, 7.65096068e-01, 5.65641999e-01, 8.49041641e-02,\n",
        "        5.82671106e-01, 8.14843714e-01, 3.37066382e-01, 9.27576602e-01,\n",
        "        7.50716984e-01, 5.74063838e-01],\n",
        "       [7.51644015e-01, 7.91489631e-02, 8.59389067e-01, 8.21504116e-01,\n",
        "        9.09871638e-01, 1.28631204e-01, 8.17800835e-02, 1.38415575e-01,\n",
        "        3.99378717e-01, 4.24306870e-01],\n",
        "       [5.62218368e-01, 1.22243546e-01, 2.01399505e-01, 8.11644375e-01,\n",
        "        4.67987567e-01, 8.07938218e-01, 7.42637832e-03, 5.51592708e-01,\n",
        "        9.31932151e-01, 5.82175434e-01],\n",
        "       [2.06095725e-01, 7.17757583e-01, 3.78985852e-01, 6.68383956e-01,\n",
        "        2.93197222e-02, 6.35900378e-01, 3.21979336e-02, 7.44780660e-01,\n",
        "        4.72912997e-01, 1.21754356e-01],\n",
        "       [5.42635918e-01, 6.67744428e-02, 6.53364897e-01, 9.96086299e-01,\n",
        "        7.69397318e-01, 5.73774099e-01, 1.02635257e-01, 6.99834049e-01,\n",
        "        6.61167860e-01, 4.90971319e-02],\n",
        "       [7.92299330e-01, 5.18716574e-01, 4.25867707e-01, 7.88187146e-01,\n",
        "        4.11569238e-01, 4.81026262e-01, 1.81628838e-01, 3.21318895e-01,\n",
        "        8.45533013e-01, 1.86903745e-01],\n",
        "       [4.17291075e-01, 9.89034534e-01, 2.36599818e-01, 9.16832328e-01,\n",
        "        9.18397486e-01, 9.12963450e-02, 4.63652730e-01, 5.02216339e-01,\n",
        "        3.13668936e-01, 4.73395362e-02],\n",
        "       [2.41685644e-01, 9.55296382e-02, 2.38249913e-01, 8.07791114e-01,\n",
        "        8.94978285e-01, 4.32228930e-02, 3.01946849e-01, 9.80582178e-01,\n",
        "        5.39504826e-01, 6.26309335e-01],\n",
        "       [5.54540846e-03, 4.84909445e-01, 9.88328516e-01, 3.75185519e-01,\n",
        "        9.70381573e-02, 4.61908758e-01, 9.63004470e-01, 3.41830611e-01,\n",
        "        7.98922718e-01, 7.98846304e-01],\n",
        "       [2.08248302e-01, 4.43367690e-01, 7.15601265e-01, 4.10519779e-01,\n",
        "        1.91006958e-01, 9.67494309e-01, 6.50750339e-01, 8.65459859e-01,\n",
        "        2.52423584e-02, 2.66905814e-01],\n",
        "       [5.02071083e-01, 6.74486384e-02, 9.93033290e-01, 2.36462399e-01,\n",
        "        3.74292195e-01, 2.14011908e-01, 1.05445869e-01, 2.32479781e-01,\n",
        "        3.00610125e-01, 6.34442270e-01],\n",
        "       [2.81234771e-01, 3.62276763e-01, 5.94284385e-03, 3.65719140e-01,\n",
        "        5.33885956e-01, 1.62015840e-01, 5.97433090e-01, 2.93152481e-01,\n",
        "        6.32050514e-01, 2.61966046e-02],\n",
        "       [8.87593448e-01, 1.61186308e-02, 1.26958027e-01, 7.77162433e-01,\n",
        "        4.58952338e-02, 7.10998714e-01, 9.71046150e-01, 8.71682942e-01,\n",
        "        7.10161626e-01, 9.58509743e-01],\n",
        "       [4.29813325e-01, 8.72878909e-01, 3.55957657e-01, 9.29763675e-01,\n",
        "        1.48777649e-01, 9.40029025e-01, 8.32716227e-01, 8.46054852e-01,\n",
        "        1.23923011e-01, 5.96486926e-01],\n",
        "       [1.63924806e-02, 7.21184373e-01, 7.73751410e-03, 8.48222747e-02,\n",
        "        2.25498408e-01, 8.75124514e-01, 3.63576323e-01, 5.39959908e-01,\n",
        "        5.68103194e-01, 2.25463361e-01],\n",
        "       [5.72146773e-01, 6.60951793e-01, 2.98245400e-01, 4.18626845e-01,\n",
        "        4.53088939e-01, 9.32350636e-01, 5.87493777e-01, 9.48252380e-01,\n",
        "        5.56034744e-01, 5.00561416e-01],\n",
        "       [3.53221106e-03, 4.80889052e-01, 9.27455008e-01, 1.98365688e-01,\n",
        "        5.20911328e-02, 4.06778902e-01, 3.72396469e-01, 8.57153058e-01,\n",
        "        2.66111158e-02, 9.20149207e-01],\n",
        "       [6.80903018e-01, 9.04226005e-01, 6.07529044e-01, 8.11953306e-01,\n",
        "        3.35543871e-01, 3.49566221e-01, 3.89874220e-01, 7.54797101e-01,\n",
        "        3.69291186e-01, 2.42219806e-01],\n",
        "       [9.37668383e-01, 9.08011079e-01, 3.48797321e-01, 6.34638071e-01,\n",
        "        2.73842216e-01, 2.06115127e-01, 3.36339533e-01, 3.27099890e-01,\n",
        "        8.82276118e-01, 8.22303832e-01],\n",
        "       [7.09623218e-01, 9.59345222e-01, 4.22543347e-01, 2.45033041e-01,\n",
        "        1.17398441e-01, 3.01053345e-01, 1.45263731e-01, 9.21861008e-02,\n",
        "        6.02932215e-01, 3.64187449e-01],\n",
        "       [5.64570367e-01, 1.91335723e-01, 6.76905870e-01, 2.15505451e-01,\n",
        "        2.78023601e-01, 7.41760433e-01, 5.59737921e-01, 3.34836423e-01,\n",
        "        5.42988777e-01, 6.93984687e-01],\n",
        "       [9.12132144e-01, 5.80713212e-01, 2.32686386e-01, 7.46697605e-01,\n",
        "        7.77769029e-01, 2.00401321e-01, 8.20574224e-01, 4.64934856e-01,\n",
        "        7.79766679e-01, 2.37478226e-01],\n",
        "       [3.32580268e-01, 9.53697145e-01, 6.57815099e-01, 7.72877812e-01,\n",
        "        6.88374341e-01, 2.04304114e-01, 4.70688760e-01, 8.08963895e-01,\n",
        "        6.75035119e-01, 6.02788571e-03],\n",
        "       [8.74077454e-02, 3.46794724e-01, 9.44365561e-01, 4.91190493e-01,\n",
        "        2.70176262e-01, 3.60423714e-01, 2.10652635e-01, 4.21200067e-01,\n",
        "        2.18035445e-01, 8.45752478e-01],\n",
        "       [4.56270605e-01, 2.79802024e-01, 9.32891667e-01, 3.14351350e-01,\n",
        "        9.09714639e-01, 4.34180908e-02, 7.07115054e-01, 4.83889043e-01,\n",
        "        4.44221050e-01, 3.63233462e-02],\n",
        "       [4.06831913e-02, 3.32753628e-01, 9.47119534e-01, 6.17659986e-01,\n",
        "        3.68874848e-01, 6.11977041e-01, 2.06131533e-01, 1.65066436e-01,\n",
        "        3.61817271e-01, 8.63353372e-01],\n",
        "       [5.09401739e-01, 2.96901524e-01, 9.50251639e-01, 8.15966070e-01,\n",
        "        3.22973937e-01, 9.72098231e-01, 9.87351120e-01, 4.08660144e-01,\n",
        "        6.55923128e-01, 4.05653208e-01],\n",
        "       [2.57348120e-01, 8.26526731e-02, 2.63610333e-01, 2.71479845e-01,\n",
        "        3.98639083e-01, 1.84886038e-01, 9.53818381e-01, 1.02879882e-01,\n",
        "        6.25208557e-01, 4.41697389e-01],\n",
        "       [4.23518062e-01, 3.71991783e-01, 8.68314683e-01, 2.80476987e-01,\n",
        "        2.05761567e-02, 9.18097019e-01, 8.64480257e-01, 2.76901782e-01,\n",
        "        5.23487568e-01, 1.09088197e-01],\n",
        "       [9.34270695e-02, 8.37466121e-01, 4.10265714e-01, 6.61716521e-01,\n",
        "        9.43200588e-01, 2.45130599e-01, 1.31598311e-02, 2.41484065e-02,\n",
        "        7.09385693e-01, 9.24551904e-01],\n",
        "       [4.67330277e-01, 3.75109136e-01, 5.42860448e-01, 8.58916819e-01,\n",
        "        6.52153850e-01, 2.32979894e-01, 7.74580181e-01, 1.34613499e-01,\n",
        "        1.65559977e-01, 6.12682283e-01],\n",
        "       [2.38783404e-01, 7.04778552e-01, 3.49518538e-01, 2.77423948e-01,\n",
        "        9.98918414e-01, 4.06161249e-02, 6.45822525e-01, 3.86995859e-02,\n",
        "        7.60210276e-01, 2.30089962e-01],\n",
        "       [8.98318663e-02, 6.48449719e-01, 7.32601225e-01, 6.78095341e-01,\n",
        "        5.19009456e-02, 2.94306934e-01, 4.51088339e-01, 2.87103295e-01,\n",
        "        8.10513437e-01, 1.31115109e-01],\n",
        "       [6.12179339e-01, 9.88214970e-01, 9.02556539e-01, 2.22157061e-01,\n",
        "        8.18876142e-05, 9.80597317e-01, 8.82712960e-01, 9.19472456e-01,\n",
        "        4.15503561e-01, 7.44615436e-01],\n",
        "       [2.12831497e-01, 3.92304063e-01, 8.51548076e-01, 1.27612218e-01,\n",
        "        8.93865347e-01, 4.96507972e-01, 4.26095665e-01, 3.05646390e-01,\n",
        "        9.16848779e-01, 5.17623484e-01],\n",
        "       [8.04026365e-01, 8.57651770e-01, 9.22382355e-01, 3.03380728e-01,\n",
        "        3.39810848e-01, 5.95073879e-01, 4.41324145e-01, 9.32842553e-01,\n",
        "        3.97564054e-01, 4.77778047e-01],\n",
        "       [6.17186069e-01, 4.04739499e-01, 9.92478430e-01, 9.88512859e-02,\n",
        "        2.20603317e-01, 3.22655141e-01, 1.47722840e-01, 2.84219235e-01,\n",
        "        7.79245317e-01, 5.22891998e-01],\n",
        "       [3.39536369e-02, 9.82622564e-01, 6.16006494e-01, 5.89394793e-02,\n",
        "        6.61168754e-01, 3.78369361e-01, 1.35673299e-01, 5.63664615e-01,\n",
        "        7.27079928e-01, 6.71126604e-01],\n",
        "       [2.47513160e-01, 5.24866223e-01, 5.37663460e-01, 7.16803372e-01,\n",
        "        3.59867334e-01, 7.97732592e-01, 6.27921820e-01, 3.83316055e-02,\n",
        "        5.46479046e-01, 8.61912072e-01],\n",
        "       [5.67574143e-01, 1.75828263e-01, 5.10376394e-01, 7.56945848e-01,\n",
        "        1.10105194e-01, 8.17099094e-01, 1.67481646e-01, 5.34076512e-01,\n",
        "        3.85743469e-01, 2.48623773e-01],\n",
        "       [6.47432506e-01, 3.73921096e-02, 7.60045826e-01, 5.26940644e-01,\n",
        "        8.75771224e-01, 5.20718336e-01, 3.50331701e-02, 1.43600971e-01,\n",
        "        7.95604587e-01, 4.91976053e-01],\n",
        "       [4.41879272e-01, 3.18434775e-01, 2.84549206e-01, 9.65886295e-01,\n",
        "        4.32969332e-01, 8.84003043e-01, 6.48163140e-01, 8.58427644e-01,\n",
        "        8.52449536e-01, 9.56312001e-01],\n",
        "       [6.97942257e-01, 8.05396914e-01, 7.33127892e-01, 6.05226815e-01,\n",
        "        7.17354119e-01, 7.15750396e-01, 4.09077927e-02, 5.16110837e-01,\n",
        "        7.92651355e-01, 2.42962182e-01],\n",
        "       [4.65147972e-01, 4.34985697e-01, 4.02787179e-01, 1.21839531e-01,\n",
        "        5.25711536e-01, 4.46248353e-01, 6.63392782e-01, 5.49413085e-01,\n",
        "        2.75429301e-02, 3.19179893e-02],\n",
        "       [7.01359808e-01, 7.07581103e-01, 9.59939122e-01, 8.76704693e-01,\n",
        "        4.68059659e-01, 6.25906527e-01, 4.57181722e-01, 2.22946241e-01,\n",
        "        3.76677006e-01, 1.03884235e-01],\n",
        "       [6.66527092e-01, 1.92030147e-01, 4.75467801e-01, 9.67436612e-01,\n",
        "        3.16689312e-02, 1.51729956e-01, 2.98579186e-01, 9.41806972e-01,\n",
        "        9.08841789e-01, 1.62000835e-01],\n",
        "       [9.81117785e-01, 7.50747502e-01, 5.39977074e-01, 9.31702912e-01,\n",
        "        8.80607128e-01, 3.91316503e-01, 6.56343222e-01, 6.47385120e-01,\n",
        "        3.26968193e-01, 1.79390177e-01],\n",
        "       [4.66809869e-01, 2.63281047e-01, 3.55065137e-01, 9.54143941e-01,\n",
        "        4.61137861e-01, 6.84891462e-01, 3.36229891e-01, 9.95861053e-01,\n",
        "        6.58767581e-01, 1.96009472e-01],\n",
        "       [9.81839970e-02, 9.43180561e-01, 9.44777846e-01, 6.21328354e-01,\n",
        "        1.69914998e-02, 2.25534886e-01, 8.01276803e-01, 8.75459850e-01,\n",
        "        4.53989804e-01, 3.65520626e-01],\n",
        "       [2.74224997e-01, 1.16970517e-01, 1.15744539e-01, 9.52602684e-01,\n",
        "        8.08626115e-01, 1.64779365e-01, 2.07050055e-01, 6.55551553e-01,\n",
        "        7.64664233e-01, 8.10314834e-01],\n",
        "       [1.63337693e-01, 9.84128296e-01, 2.27802068e-01, 5.89415431e-01,\n",
        "        5.87615728e-01, 9.67361867e-01, 6.57667458e-01, 5.84904253e-01,\n",
        "        5.18772602e-01, 7.64657557e-01],\n",
        "       [1.06055260e-01, 2.09190114e-03, 9.52488840e-01, 4.98657674e-01,\n",
        "        3.28335375e-01, 3.68053257e-01, 8.03843319e-01, 3.82370204e-01,\n",
        "        7.70169199e-01, 4.40461993e-01],\n",
        "       [8.44077468e-01, 7.62040615e-02, 4.81128335e-01, 4.66849715e-01,\n",
        "        2.64327973e-01, 9.43614721e-01, 9.05028462e-01, 4.43596303e-01,\n",
        "        9.71596092e-02, 2.06783146e-01],\n",
        "       [2.71491826e-01, 4.84219760e-01, 3.38377118e-01, 7.74136066e-01,\n",
        "        4.76026595e-01, 8.70370507e-01, 9.95781779e-01, 2.19835952e-01,\n",
        "        6.11671388e-01, 8.47502291e-01],\n",
        "       [9.45236623e-01, 2.90086418e-01, 7.27042735e-01, 1.50161488e-02,\n",
        "        8.79142463e-01, 6.39385507e-02, 7.33395398e-01, 9.94610369e-01,\n",
        "        5.01189768e-01, 2.09333986e-01],\n",
        "       [5.94643593e-01, 6.24149978e-01, 6.68072760e-01, 1.72611743e-01,\n",
        "        8.98712695e-01, 6.20991349e-01, 4.35687043e-02, 6.84041083e-01,\n",
        "        1.96084052e-01, 2.73407809e-02],\n",
        "       [5.50953269e-01, 8.13313663e-01, 8.59941125e-01, 1.03520922e-01,\n",
        "        6.63042784e-01, 7.10075200e-01, 2.94516981e-01, 9.71364021e-01,\n",
        "        2.78687477e-01, 6.99821860e-02],\n",
        "       [5.19280374e-01, 6.94314897e-01, 2.44659781e-01, 3.38582188e-01,\n",
        "        5.63627958e-01, 8.86678159e-01, 7.47325897e-01, 2.09591955e-01,\n",
        "        2.51777083e-01, 5.23880661e-01],\n",
        "       [7.68958688e-01, 6.18761778e-01, 5.01324296e-01, 5.97125351e-01,\n",
        "        7.56060004e-01, 5.37079811e-01, 8.97752762e-01, 9.47067499e-01,\n",
        "        9.15354490e-01, 7.54518330e-01],\n",
        "       [2.46321008e-01, 3.85271460e-01, 2.79999942e-01, 6.57660246e-01,\n",
        "        3.24221611e-01, 7.54391611e-01, 1.13509081e-01, 7.75364757e-01,\n",
        "        5.85901976e-01, 8.35388660e-01],\n",
        "       [4.30875659e-01, 6.24964476e-01, 5.54412127e-01, 9.75671291e-01,\n",
        "        7.55474389e-01, 5.44813275e-01, 1.74032092e-01, 9.04114246e-01,\n",
        "        2.05837786e-01, 6.50043249e-01],\n",
        "       [9.36471879e-01, 2.23579630e-01, 2.25923538e-01, 8.51818919e-01,\n",
        "        8.27655017e-01, 3.51703346e-01, 2.65096277e-01, 1.27388477e-01,\n",
        "        9.87936080e-01, 8.35343122e-01],\n",
        "       [8.99391592e-01, 5.13679326e-01, 1.14384830e-01, 5.25803380e-02,\n",
        "        3.30582112e-01, 9.20330405e-01, 9.47581828e-01, 8.41163874e-01,\n",
        "        1.58679143e-01, 4.19923156e-01],\n",
        "       [2.46242926e-01, 2.05349773e-01, 6.84825838e-01, 4.86111671e-01,\n",
        "        3.24909657e-01, 1.00214459e-01, 5.44763386e-01, 3.47025156e-01,\n",
        "        3.91095817e-01, 3.10508728e-01],\n",
        "       [3.87195200e-01, 5.55859566e-01, 1.41438060e-02, 8.47647011e-01,\n",
        "        9.21919882e-01, 5.50529718e-01, 2.68021107e-01, 9.90239024e-01,\n",
        "        3.83194029e-01, 6.93655372e-01],\n",
        "       [6.89952552e-01, 4.34309065e-01, 1.99158162e-01, 9.66579378e-01,\n",
        "        6.36908561e-02, 4.85149384e-01, 2.20730707e-01, 2.93974131e-01,\n",
        "        8.28527331e-01, 3.67265552e-01],\n",
        "       [8.33482668e-02, 1.96309000e-01, 8.60373437e-01, 9.77028847e-01,\n",
        "        2.67982155e-01, 6.75408959e-01, 8.11989978e-02, 7.23465621e-01,\n",
        "        4.16436613e-01, 9.18159902e-01],\n",
        "       [3.11536163e-01, 9.41466987e-01, 5.03247440e-01, 3.48892927e-01,\n",
        "        6.47019625e-01, 2.49746203e-01, 2.29763597e-01, 1.96346447e-01,\n",
        "        9.59899545e-01, 4.92913723e-01],\n",
        "       [7.51614988e-01, 4.73991871e-01, 5.87540150e-01, 5.84138989e-01,\n",
        "        9.79886293e-01, 6.68433130e-01, 2.39769474e-01, 1.51976589e-02,\n",
        "        2.18682140e-01, 4.55519646e-01],\n",
        "       [3.93420339e-01, 8.12326252e-01, 7.85556734e-01, 8.90959650e-02,\n",
        "        9.52010751e-01, 5.27456701e-01, 5.96403956e-01, 4.05056775e-01,\n",
        "        6.49500966e-01, 8.71326327e-01],\n",
        "       [6.73935950e-01, 9.70098555e-01, 7.01122224e-01, 8.21720719e-01,\n",
        "        4.50395830e-02, 6.72698498e-01, 6.54752672e-01, 1.01746053e-01,\n",
        "        8.42387497e-01, 6.14172399e-01],\n",
        "       [9.83280912e-02, 5.94467103e-01, 4.78415847e-01, 2.33293563e-01,\n",
        "        1.97560899e-02, 3.65567267e-01, 6.19851053e-01, 3.29279125e-01,\n",
        "        3.07254642e-01, 7.51121223e-01],\n",
        "       [7.58624673e-01, 7.18765855e-01, 1.01181954e-01, 5.16165972e-01,\n",
        "        5.57798684e-01, 7.44804502e-01, 9.03177738e-01, 3.69038880e-01,\n",
        "        4.28663462e-01, 7.32767463e-01],\n",
        "       [6.62636399e-01, 5.57869911e-01, 3.50139618e-01, 1.95352346e-01,\n",
        "        1.83807373e-01, 8.15832913e-02, 8.12008530e-02, 8.45798194e-01,\n",
        "        3.83672744e-01, 6.07396215e-02],\n",
        "       [8.96425664e-01, 2.23270476e-01, 2.68124431e-01, 1.94497839e-01,\n",
        "        9.67501044e-01, 1.12540089e-01, 7.22163260e-01, 9.32088733e-01,\n",
        "        6.68001294e-01, 8.58726621e-01],\n",
        "       [2.42447108e-01, 6.73927963e-01, 7.00871348e-01, 4.58332509e-01,\n",
        "        8.70545626e-01, 6.94386125e-01, 8.94877791e-01, 7.53204346e-01,\n",
        "        5.20290434e-01, 4.98688221e-01],\n",
        "       [4.53727633e-01, 2.16468628e-02, 5.35141408e-01, 4.22973245e-01,\n",
        "        1.57533601e-01, 1.19069695e-01, 4.49351877e-01, 3.99130546e-02,\n",
        "        9.86579895e-01, 3.78120929e-01],\n",
        "       [3.82109195e-01, 5.11263013e-02, 4.26672339e-01, 1.57454368e-02,\n",
        "        3.00936326e-02, 3.39099228e-01, 8.20968926e-01, 4.58821088e-01,\n",
        "        1.48405796e-02, 1.63220033e-01],\n",
        "       [7.39922702e-01, 7.38293707e-01, 7.54522920e-01, 3.51669371e-01,\n",
        "        3.52276951e-01, 8.02075684e-01, 3.98137897e-01, 7.27191031e-01,\n",
        "        5.81122994e-01, 3.64341676e-01],\n",
        "       [8.00065175e-02, 1.16125375e-01, 8.89558733e-01, 4.52340513e-01,\n",
        "        9.94004548e-01, 3.63896936e-01, 2.49954298e-01, 3.50539327e-01,\n",
        "        3.43086094e-01, 6.37356758e-01],\n",
        "       [1.27375638e-02, 7.63268650e-01, 4.16414618e-01, 4.32239205e-01,\n",
        "        4.81115013e-01, 4.49212462e-01, 4.97470886e-01, 3.45904320e-01,\n",
        "        4.53346133e-01, 4.04651344e-01],\n",
        "       [5.18242717e-01, 6.23269081e-01, 2.41040602e-01, 5.08437157e-01,\n",
        "        5.94621897e-01, 1.69483144e-02, 5.20493746e-01, 2.39293247e-01,\n",
        "        4.04538542e-01, 8.26530159e-01],\n",
        "       [3.26235592e-01, 4.83216912e-01, 2.47411542e-02, 3.08750868e-01,\n",
        "        6.39721096e-01, 3.15161765e-01, 2.05797508e-01, 2.90655673e-01,\n",
        "        9.54378307e-01, 8.68018195e-02],\n",
        "       [4.63357776e-01, 5.83869033e-02, 5.38658261e-01, 1.46035731e-01,\n",
        "        6.34084821e-01, 2.64397472e-01, 6.90915406e-01, 3.47146064e-01,\n",
        "        4.16848855e-03, 2.94894695e-01]],np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF55WjjpsEhq",
        "outputId": "399fa731-1e6a-40ad-82f4-e27554307bfc"
      },
      "source": [
        "# Define the first dense layer\n",
        "dense1 = keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
        "\n",
        "# Define a dense layer with 3 output nodes\n",
        "dense2 = keras.layers.Dense(3, activation='sigmoid')(dense1)\n",
        "\n",
        "# Define a dense layer with 1 output node\n",
        "predictions = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "# Print the shapes of dense1, dense2, and predictions\n",
        "print('\\n shape of dense1: ', dense1.shape)\n",
        "print('\\n shape of dense2: ', dense2.shape)\n",
        "print('\\n shape of predictions: ', predictions.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " shape of dense1:  TensorShape([100, 7])\n",
            "\n",
            " shape of dense2:  TensorShape([100, 3])\n",
            "\n",
            " shape of predictions:  TensorShape([100, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoYmqKlSshUp"
      },
      "source": [
        "With just 8 lines of code, you were able to define 2 dense hidden layers and an output layer. This is the advantage of using high-level operations in tensorflow. Note that each layer has 100 rows because the input data contains 100 examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N2tbGo-wLDm"
      },
      "source": [
        "## Binary Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "41oNNa4ZwRaC",
        "outputId": "9b0e2bea-c622-4bed-cafe-5816d322f4f1"
      },
      "source": [
        "credit_card"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default.payment.next.month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>3913.0</td>\n",
              "      <td>3102.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>120000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2682.0</td>\n",
              "      <td>1725.0</td>\n",
              "      <td>2682.0</td>\n",
              "      <td>3272.0</td>\n",
              "      <td>3455.0</td>\n",
              "      <td>3261.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29239.0</td>\n",
              "      <td>14027.0</td>\n",
              "      <td>13559.0</td>\n",
              "      <td>14331.0</td>\n",
              "      <td>14948.0</td>\n",
              "      <td>15549.0</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46990.0</td>\n",
              "      <td>48233.0</td>\n",
              "      <td>49291.0</td>\n",
              "      <td>28314.0</td>\n",
              "      <td>28959.0</td>\n",
              "      <td>29547.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8617.0</td>\n",
              "      <td>5670.0</td>\n",
              "      <td>35835.0</td>\n",
              "      <td>20940.0</td>\n",
              "      <td>19146.0</td>\n",
              "      <td>19131.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>36681.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>29996</td>\n",
              "      <td>220000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>188948.0</td>\n",
              "      <td>192815.0</td>\n",
              "      <td>208365.0</td>\n",
              "      <td>88004.0</td>\n",
              "      <td>31237.0</td>\n",
              "      <td>15980.0</td>\n",
              "      <td>8500.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>5003.0</td>\n",
              "      <td>3047.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>29997</td>\n",
              "      <td>150000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1683.0</td>\n",
              "      <td>1828.0</td>\n",
              "      <td>3502.0</td>\n",
              "      <td>8979.0</td>\n",
              "      <td>5190.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1837.0</td>\n",
              "      <td>3526.0</td>\n",
              "      <td>8998.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>29998</td>\n",
              "      <td>30000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3565.0</td>\n",
              "      <td>3356.0</td>\n",
              "      <td>2758.0</td>\n",
              "      <td>20878.0</td>\n",
              "      <td>20582.0</td>\n",
              "      <td>19357.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22000.0</td>\n",
              "      <td>4200.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>3100.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>29999</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1645.0</td>\n",
              "      <td>78379.0</td>\n",
              "      <td>76304.0</td>\n",
              "      <td>52774.0</td>\n",
              "      <td>11855.0</td>\n",
              "      <td>48944.0</td>\n",
              "      <td>85900.0</td>\n",
              "      <td>3409.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>1926.0</td>\n",
              "      <td>52964.0</td>\n",
              "      <td>1804.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>30000</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47929.0</td>\n",
              "      <td>48905.0</td>\n",
              "      <td>49764.0</td>\n",
              "      <td>36535.0</td>\n",
              "      <td>32428.0</td>\n",
              "      <td>15313.0</td>\n",
              "      <td>2078.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1430.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  LIMIT_BAL  SEX  ...  PAY_AMT5  PAY_AMT6  default.payment.next.month\n",
              "0          1    20000.0    2  ...       0.0       0.0                           1\n",
              "1          2   120000.0    2  ...       0.0    2000.0                           1\n",
              "2          3    90000.0    2  ...    1000.0    5000.0                           0\n",
              "3          4    50000.0    2  ...    1069.0    1000.0                           0\n",
              "4          5    50000.0    1  ...     689.0     679.0                           0\n",
              "...      ...        ...  ...  ...       ...       ...                         ...\n",
              "29995  29996   220000.0    1  ...    5000.0    1000.0                           0\n",
              "29996  29997   150000.0    1  ...       0.0       0.0                           0\n",
              "29997  29998    30000.0    1  ...    2000.0    3100.0                           1\n",
              "29998  29999    80000.0    1  ...   52964.0    1804.0                           1\n",
              "29999  30000    50000.0    1  ...    1000.0    1000.0                           1\n",
              "\n",
              "[30000 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oVweTGQshv2",
        "outputId": "23d1b00e-cb3d-4ca9-b34a-f5c009b2d276"
      },
      "source": [
        "default = tf.cast(credit_card['default.payment.next.month'],int32)\n",
        "bill_amounts = tf.cast(credit_card[['BILL_AMT6','BILL_AMT5','BILL_AMT4','BILL_AMT3','BILL_AMT2','BILL_AMT1']],float32)\n",
        "\n",
        "# Construct input layer from features\n",
        "inputs = constant(bill_amounts, float32)\n",
        "\n",
        "# Define first dense layer\n",
        "dense1 = keras.layers.Dense(3, activation='relu')(inputs)\n",
        "\n",
        "# Define second dense layer\n",
        "dense2 = keras.layers.Dense(2, activation='relu')(dense1)\n",
        "\n",
        "# Define output layer\n",
        "outputs = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "# Print error for first five examples\n",
        "error = default[:5] - outputs.numpy()[:5]\n",
        "print(error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 0 0 0]\n",
            " [0 0 -1 -1 -1]\n",
            " [1 1 0 0 0]\n",
            " [0 0 -1 -1 -1]\n",
            " [0 0 -1 -1 -1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygQNEY26xf5i"
      },
      "source": [
        "If you run the code several times, you'll notice that the errors change each time. This is because you're using an untrained model with randomly initialized parameters. Furthermore, the errors fall on the interval between -1 and 1 because default is a binary variable that takes on values of 0 and 1 and outputs is a probability between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VfE9-t3yO-A",
        "outputId": "42061295-7263-4ad6-9537-8ff9dce26bb7"
      },
      "source": [
        "# Construct input layer from borrower features\n",
        "inputs = constant(borrower_features,float32)\n",
        "\n",
        "# Define first dense layer\n",
        "dense1 = keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
        "\n",
        "# Define second dense layer\n",
        "dense2 = keras.layers.Dense(8, activation='relu')(dense1)\n",
        "\n",
        "# Define output layer\n",
        "outputs = keras.layers.Dense(6,activation='softmax')(dense2)\n",
        "\n",
        "# Print first five predictions\n",
        "print(outputs.numpy()[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array([[0.03558748, 0.09780829, 0.03445338, 0.5013167 , 0.2683619 ,\n",
            "        0.06247229],\n",
            "       [0.04333224, 0.11216097, 0.04004329, 0.48199517, 0.25440624,\n",
            "        0.06806216],\n",
            "       [0.03847786, 0.10541128, 0.03384403, 0.51441914, 0.24807556,\n",
            "        0.05977214],\n",
            "       [0.04131056, 0.10708534, 0.040503  , 0.47482824, 0.26750076,\n",
            "        0.06877214],\n",
            "       [0.03621254, 0.09985607, 0.03627057, 0.49359602, 0.26955548,\n",
            "        0.06450941]], dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy_XO2lgyQey"
      },
      "source": [
        "Notice that each row of outputs sums to one. This is because a row contains the predicted class probabilities for one example. As with the previous exercise, our predictions are not yet informative, since we are using an untrained model with randomly initialized parameters. This is why the model tends to assign similar probabilities to each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrjjiKTayWc4"
      },
      "source": [
        "## The Dangers of Local Minima\n",
        "In this exercise, you will try to find the global minimum of loss_function() using keras.optimizers.SGD(). You will do this twice, each time with a different initial value of the input to loss_function(). First, you will use x_1, which is a variable with an initial value of 6.0. Second, you will use x_2, which is a variable with an initial value of 0.3. Note that loss_function() has been defined and is available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nRan7oB0TLG"
      },
      "source": [
        "# Define the model function\n",
        "def model(bias, weights, features = borrower_features):\n",
        "  product = tf.matmul(features, weights)\n",
        "  return tf.keras.activations.sigmoid(product+bias)\n",
        "\n",
        "# Compute the predicted values and loss\n",
        "def loss_function(bias, weights, targets = default, features = borrower_features):\n",
        "  predictions = model(bias, weights)\n",
        "  return tf.keras.losses.binary_crossentropy(targets, predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18wu0k8r2D6D"
      },
      "source": [
        "## Initialization in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74_o0tRA2E4p"
      },
      "source": [
        "# Define the layer 1 weights\n",
        "w1 = Variable(random.normal([10, 23]))\n",
        "\n",
        "# Initialize the layer 1 bias\n",
        "b1 = Variable(ones([23,100]))\n",
        "\n",
        "# Define the layer 2 weights\n",
        "w2 = Variable(random.normal([7,1]))\n",
        "\n",
        "# Define the layer 2 bias\n",
        "b2 = Variable([0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUdFcidI2Ocl"
      },
      "source": [
        "## Defining the Model and Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1DWWLzK2cZs"
      },
      "source": [
        "# Define the model\n",
        "def model(w1, b1, w2, b2, features = borrower_features):\n",
        "\t# Apply relu activation functions to layer 1\n",
        "\tlayer1 = keras.activations.relu(matmul(features, w1) + b1)\n",
        "    # Apply dropout\n",
        "\tdropout = keras.layers.Dropout(0.25)(layer1)\n",
        "\treturn keras.activations.sigmoid(matmul(dropout, w2) + b2)\n",
        "\n",
        "# Define the loss function\n",
        "def loss_function(w1, b1, w2, b2, features = borrower_features, targets = default):\n",
        "\tpredictions = model(w1, b1, w2, b2)\n",
        "\t# Pass targets and predictions to the cross entropy loss\n",
        "\treturn keras.losses.binary_crossentropy(targets, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq9DdViP2dnw"
      },
      "source": [
        "## Training neural networks with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpNSWYaC3Yyd"
      },
      "source": [
        "test_features = tf.cast(credit_card.iloc[:,:-1],float32)\n",
        "test_targets = tf.cast(credit_card.iloc[:,-1],int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "0yMYAT1-2gJg",
        "outputId": "50eb0f5b-1c46-486d-a73c-55fa84285967"
      },
      "source": [
        "# Train the model\n",
        "for j in range(100):\n",
        "    # Complete the optimizer\n",
        "\topt.minimize(lambda: loss_function(w1, b1, w2, b2), \n",
        "                 var_list=[w1, b1, w2, b2])\n",
        "\n",
        "# Make predictions with model\n",
        "model_predictions = model(w1, b1, w2, b2, test_features)\n",
        "\n",
        "# Construct the confusion matrix\n",
        "confusion_matrix(test_targets, model_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-91e54e0cc634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Complete the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \topt.minimize(lambda: loss_function(w1, b1, w2, b2), \n\u001b[0;32m----> 5\u001b[0;31m                  var_list=[w1, b1, w2, b2])\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Make predictions with model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \"\"\"\n\u001b[1;32m    496\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 497\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[1;32m    498\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m           \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-91e54e0cc634>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Complete the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \topt.minimize(lambda: loss_function(w1, b1, w2, b2), \n\u001b[0m\u001b[1;32m      5\u001b[0m                  var_list=[w1, b1, w2, b2])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-76ca3e21fab6>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(w1, b1, w2, b2, features, targets)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Define the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mborrower_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Pass targets and predictions to the cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-76ca3e21fab6>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(w1, b1, w2, b2, features)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mborrower_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# Apply relu activation functions to layer 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Apply dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    470\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [100,23] vs. [23,100] [Op:AddV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqrqgyeKZJ-Q"
      },
      "source": [
        "# High Level APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF5uSL2KaV9a"
      },
      "source": [
        "## The sequential model in Keras\n",
        "In chapter 3, we used components of the keras API in tensorflow to define a neural network, but we stopped short of using its full capabilities to streamline model definition and training. In this exercise, you will use the keras sequential model API to define a neural network that can be used to classify images of sign language letters. You will also use the .summary() method to print the model's architecture, including the shape and number of parameters associated with each layer.\n",
        "\n",
        "Note that the images were reshaped from (28, 28) to (784,), so that they could be used as inputs to a dense layer. Additionally, note that keras has been imported from tensorflow for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AI7V7QpZN6v",
        "outputId": "13592e5e-204e-422b-8d76-94a4ec823195"
      },
      "source": [
        "# Define a Keras sequential model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Define the first dense layer\n",
        "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
        "\n",
        "# Define the second dense layer\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "\n",
        "# Define the output layer\n",
        "model.add(keras.layers.Dense(4, activation='softmax'))\n",
        "\n",
        "# Print the model architecture\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 16)                12560     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4)                 36        \n",
            "=================================================================\n",
            "Total params: 12,732\n",
            "Trainable params: 12,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXzmWAk5a2c2"
      },
      "source": [
        "Notice that we've defined a model, but we haven't compiled it. The compilation step in keras allows us to set the optimizer, loss function, and other useful training parameters in a single line of code. Furthermore, the .summary() method allows us to view the model's architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KKqsi1ja6S1"
      },
      "source": [
        "## Compiling a sequential model\n",
        "In this exercise, you will work towards classifying letters from the Sign Language MNIST dataset; however, you will adopt a different network architecture than what you used in the previous exercise. There will be fewer layers, but more nodes. You will also apply dropout to prevent overfitting. Finally, you will compile the model to use the adam optimizer and the categorical_crossentropy loss. You will also use a method in keras to summarize your model's architecture. Note that keras has been imported from tensorflow for you and a sequential keras model has been defined as model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVGk0dDsa3xX",
        "outputId": "697c14cb-8839-4cea-ef4d-0ea702127ced"
      },
      "source": [
        "# Define the first dense layer\n",
        "model.add(keras.layers.Dense(16, activation = 'sigmoid', input_shape = (784,)))\n",
        "\n",
        "# Apply dropout to the first layer's output\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "# Define the output layer\n",
        "model.add(keras.layers.Dense(4, activation = 'softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile('adam', loss='categorical_crossentropy')\n",
        "\n",
        "# Print a model summary\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 16)                12560     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 16)                80        \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 4)                 68        \n",
            "=================================================================\n",
            "Total params: 12,880\n",
            "Trainable params: 12,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8TuakqlbY_v"
      },
      "source": [
        "Notice that printing the .summary() method shows the layer type, output shape, and number of parameters of each layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk5OI3BGbhi_"
      },
      "source": [
        "## Defining a multiple input model\n",
        "In some cases, the sequential API will not be sufficiently flexible to accommodate your desired model architecture and you will need to use the functional API instead. If, for instance, you want to train two models with different architectures jointly, you will need to use the functional API to do this. In this exercise, we will see how to do this. We will also use the .summary() method to examine the joint model's architecture.\n",
        "\n",
        "Note that keras has been imported from tensorflow for you. Additionally, the input layers of the first and second models have been defined as m1_inputs and m2_inputs, respectively. Note that the two models have the same architecture, but one of them uses a sigmoid activation in the first layer and the other uses a relu.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qJuYPS2bZjX",
        "outputId": "e561d0ca-9dd6-4efb-d5d0-f805227da53b"
      },
      "source": [
        "m1_inputs = tf.keras.Input(shape=(784,))\n",
        "m2_inputs = tf.keras.Input(shape=(784,))\n",
        "\n",
        "# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n",
        "m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n",
        "m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n",
        "\n",
        "# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n",
        "m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n",
        "m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n",
        "\n",
        "# Merge model outputs and define a functional model\n",
        "merged = keras.layers.add([m1_layer2, m2_layer2])\n",
        "model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n",
        "\n",
        "# Print a model summary\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 784)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 784)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 12)           9420        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 12)           9420        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 4)            52          dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 4)            52          dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 4)            0           dense_15[0][0]                   \n",
            "                                                                 dense_17[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 18,944\n",
            "Trainable params: 18,944\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxSYSx40cQJC"
      },
      "source": [
        "Notice that the .summary() method yields a new column: connected to. This column tells you how layers connect to each other within the network. We can see that dense_2, for instance, is connected to the input_2 layer. We can also see that the add layer, which merged the two models, connected to both dense_1 and dense_3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkICG8bcdPZ6"
      },
      "source": [
        "## Training with Keras\n",
        "In this exercise, we return to our sign language letter classification problem. We have 2000 images of four letters--A, B, C, and D--and we want to classify them with a high level of accuracy. We will complete all parts of the problem, including the model definition, compilation, and training.\n",
        "\n",
        "Note that keras has been imported from tensorflow for you. Additionally, the features are available as sign_language_features and the targets are available as sign_language_labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kroBh3idS0d"
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGUobtyAhliS"
      },
      "source": [
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(128)\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1kujIsFhogB"
      },
      "source": [
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NAyc5UjhrXG",
        "outputId": "0704c466-d761-45d4-928b-9841da6fd741"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128,activation='relu'),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=6,\n",
        "    validation_data=ds_test,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "469/469 [==============================] - 10s 7ms/step - loss: 0.5942 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.1876 - val_sparse_categorical_accuracy: 0.9477\n",
            "Epoch 2/6\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1701 - sparse_categorical_accuracy: 0.9511 - val_loss: 0.1376 - val_sparse_categorical_accuracy: 0.9596\n",
            "Epoch 3/6\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1203 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.1120 - val_sparse_categorical_accuracy: 0.9662\n",
            "Epoch 4/6\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9728 - val_loss: 0.0969 - val_sparse_categorical_accuracy: 0.9700\n",
            "Epoch 5/6\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9782 - val_loss: 0.0905 - val_sparse_categorical_accuracy: 0.9711\n",
            "Epoch 6/6\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.0812 - val_sparse_categorical_accuracy: 0.9746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde27663a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7UeCMjNiq6I"
      },
      "source": [
        "With the keras API, you only needed 14 lines of code to define, compile, train, and validate a model. You may have noticed that your model performed quite well. In just 10 epochs, we achieved a classification accuracy of over 90% in the validation sample!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWEPHxtCksgx"
      },
      "source": [
        "## Preparing to train with Estimators\n",
        "For this exercise, we'll return to the King County housing transaction dataset from chapter 2. We will again develop and train a machine learning model to predict house prices; however, this time, we'll do it using the estimator API.\n",
        "\n",
        "Rather than completing everything in one step, we'll break this procedure down into parts. We'll begin by defining the feature columns and loading the data. In the next exercise, we'll define and train a premade estimator. Note that feature_column has been imported for you from tensorflow. Additionally, numpy has been imported as np, and the Kings County housing dataset is available as a pandas DataFrame: housing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "6i4ka6sZk8BS",
        "outputId": "a03367ba-6461-424f-d2f6-492766cc5247"
      },
      "source": [
        "housing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21608</th>\n",
              "      <td>263000018</td>\n",
              "      <td>20140521T000000</td>\n",
              "      <td>360000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1530</td>\n",
              "      <td>1131</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1530</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>98103</td>\n",
              "      <td>47.6993</td>\n",
              "      <td>-122.346</td>\n",
              "      <td>1530</td>\n",
              "      <td>1509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21609</th>\n",
              "      <td>6600060120</td>\n",
              "      <td>20150223T000000</td>\n",
              "      <td>400000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2310</td>\n",
              "      <td>5813</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>2310</td>\n",
              "      <td>0</td>\n",
              "      <td>2014</td>\n",
              "      <td>0</td>\n",
              "      <td>98146</td>\n",
              "      <td>47.5107</td>\n",
              "      <td>-122.362</td>\n",
              "      <td>1830</td>\n",
              "      <td>7200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21610</th>\n",
              "      <td>1523300141</td>\n",
              "      <td>20140623T000000</td>\n",
              "      <td>402101.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1020</td>\n",
              "      <td>1350</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1020</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>98144</td>\n",
              "      <td>47.5944</td>\n",
              "      <td>-122.299</td>\n",
              "      <td>1020</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21611</th>\n",
              "      <td>291310100</td>\n",
              "      <td>20150116T000000</td>\n",
              "      <td>400000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1600</td>\n",
              "      <td>2388</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1600</td>\n",
              "      <td>0</td>\n",
              "      <td>2004</td>\n",
              "      <td>0</td>\n",
              "      <td>98027</td>\n",
              "      <td>47.5345</td>\n",
              "      <td>-122.069</td>\n",
              "      <td>1410</td>\n",
              "      <td>1287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21612</th>\n",
              "      <td>1523300157</td>\n",
              "      <td>20141015T000000</td>\n",
              "      <td>325000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1020</td>\n",
              "      <td>1076</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1020</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>98144</td>\n",
              "      <td>47.5941</td>\n",
              "      <td>-122.299</td>\n",
              "      <td>1020</td>\n",
              "      <td>1357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21613 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id             date  ...  sqft_living15  sqft_lot15\n",
              "0      7129300520  20141013T000000  ...           1340        5650\n",
              "1      6414100192  20141209T000000  ...           1690        7639\n",
              "2      5631500400  20150225T000000  ...           2720        8062\n",
              "3      2487200875  20141209T000000  ...           1360        5000\n",
              "4      1954400510  20150218T000000  ...           1800        7503\n",
              "...           ...              ...  ...            ...         ...\n",
              "21608   263000018  20140521T000000  ...           1530        1509\n",
              "21609  6600060120  20150223T000000  ...           1830        7200\n",
              "21610  1523300141  20140623T000000  ...           1020        2007\n",
              "21611   291310100  20150116T000000  ...           1410        1287\n",
              "21612  1523300157  20141015T000000  ...           1020        1357\n",
              "\n",
              "[21613 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwTUJ-N6i4d1"
      },
      "source": [
        "# Define feature columns for bedrooms and bathrooms\n",
        "bedrooms = feature_column.numeric_column(\"bedrooms\")\n",
        "bathrooms = feature_column.numeric_column('bathrooms')\n",
        "\n",
        "# Define the list of feature columns\n",
        "feature_list = [bedrooms, bathrooms]\n",
        "\n",
        "def input_fn():\n",
        "\t# Define the labels\n",
        "\tlabels = np.array(housing['price'])\n",
        "\t# Define the features\n",
        "\tfeatures = {'bedrooms':np.array(housing['bedrooms']), \n",
        "                'bathrooms':np.array(housing['bathrooms'])}\n",
        "\treturn features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9cZwTXBlOrU",
        "outputId": "3d064b1b-505a-4a58-d852-5422ef2a2b1d"
      },
      "source": [
        "# Define the model and set the number of steps\n",
        "model = estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[2,2])\n",
        "model.train(input_fn, steps=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp906hi14z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp906hi14z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp906hi14z', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp906hi14z', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:83: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:83: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp906hi14z/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp906hi14z/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 426471650000.0, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 426471650000.0, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp906hi14z/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp906hi14z/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 426471650000.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 426471650000.0.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressorV2 at 0x7fde281b1a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjHqH69Glt96",
        "outputId": "de514f45-cfa8-459c-b82a-9d6bfefa27d5"
      },
      "source": [
        "# Define the model and set the number of steps\n",
        "model = estimator.LinearRegressor(feature_columns=feature_list)\n",
        "model.train(input_fn, steps=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8ppwt3v5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8ppwt3v5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8ppwt3v5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8ppwt3v5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp8ppwt3v5/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp8ppwt3v5/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 426471400000.0, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 426471400000.0, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2 into /tmp/tmp8ppwt3v5/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2 into /tmp/tmp8ppwt3v5/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 426469850000.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 426469850000.0.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x7fde281b1190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}